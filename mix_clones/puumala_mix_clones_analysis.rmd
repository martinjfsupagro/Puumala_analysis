---
title: "R analysis of Puumala project, clones mix"
output:
  pdf_document: default
  html_notebook: default
---



```{r}
library(dada2); packageVersion("dada2")
```

```{r}
path <- setwd("C:/Users/martinjf/Desktop/Travail/Recherche/Projets/Guillaume -puumala/Puumala_analysis/mix_clones/")
list.files(path, pattern="*.fastq.gz")
```

```{r}
# Forward and reverse fastq filenames have format: SAMPLENAME_R1_001.fastq and SAMPLENAME_R2_001.fastq
fnFs <- sort(list.files(path, pattern="_R1_001.fastq.gz", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_R2_001.fastq.gz", full.names = TRUE))
# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq.gz
sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1)
```

```{r}
plotQualityProfile(fnFs[1:6])
```
```{r}
plotQualityProfile(fnRs[1:6])
```
```{r}
# Place filtered files in filtered/ subdirectory
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
```

```{r}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, maxN=0, rm.phix=TRUE, compress=TRUE, multithread=FALSE) # On Windows set multithread=FALSE
out
```

```{r}
errF <- learnErrors(filtFs, multithread=TRUE)
```

```{r}
errR <- learnErrors(filtRs, multithread=TRUE)
```
```{r}
plotErrors(errF, nominalQ=TRUE)
```
```{r}
derepFs <- derepFastq(filtFs, verbose=TRUE)
derepRs <- derepFastq(filtRs, verbose=TRUE)
# Name the derep-class objects by the sample names
names(derepFs) <- sample.names
names(derepRs) <- sample.names
```

```{r}
dadaFs <- dada(derepFs, err=errF, multithread=FALSE)
```

```{r}
dadaRs <- dada(derepRs, err=errR, multithread=FALSE)
```

```{r}
dadaFs[[1]]
```

```{r}
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose=TRUE)
```
```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab)
```
There is a total of 4 variants in the 6 samples

```{r}
# Inspect distribution of sequence lengths
table(nchar(getSequences(seqtab)))
```
The size of all 4 variants is 236 bases
```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="per-sample", multithread=FALSE, verbose=TRUE)
dim(seqtab.nochim)
```
No chimera was detected with the "per-sample" algorithm.
```{r}
sum(seqtab.nochim)/sum(seqtab)

```
100% of the variants were therefore kept for further analysis

```{r}
# Assumes seqtab_nochim is your sequence table of merged sequences
seqlens <- nchar(getSequences(seqtab.nochim))
plot(sort(seqlens))
MINLEN <- 0
MAXLEN <- 500
seqtab.nochim.length_filt <- seqtab.nochim[,seqlens >= MINLEN & seqlens <= MAXLEN]
dim(seqtab.nochim.length_filt)
seqlens_filt <- nchar(getSequences(seqtab.nochim.length_filt))
plot(sort(seqlens_filt))

abundances <- colSums(seqtab.nochim.length_filt)
plot(sort(abundances))
MINABUND <- 1
seqtab.nochim.length_abundance_filt <- seqtab.nochim.length_filt[,abundances >= MINABUND]
dim(seqtab.nochim.length_abundance_filt)
asvs.table <- seqtab.nochim.length_abundance_filt
saveRDS(asvs.table, "./asvs_table.rds") # CHANGE ME to where you want sequence table saved
uniquesToFasta(asvs.table, fout="asvs.fasta")

```

```{r}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
track
write.csv(seqtab.nochim.length_abundance_filt, file = "asvs.csv")
```

